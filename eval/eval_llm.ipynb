{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import Utils, Fairness, compute_group_scores\n",
    "import pandas as pd\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.dpi'] = 200\n",
    "plt.rcParams['savefig.dpi'] = 600\n",
    "\n",
    "list_data = [\"ml-1m\", \"jobrec\", \"lfm-1b\"]\n",
    "\n",
    "map_columns = {\n",
    "                #datasets\n",
    "                \"ml-1m\":\"ML-1M\",\n",
    "               \"jobrec\":\"JobRec\",\n",
    "               \"lfm-1b\":\"LFM-1B\",\n",
    "\n",
    "                #models\n",
    "               'meta-llama_neutral':\"Llama-3.1-8B (NS)\",\n",
    "                'meta-llama_sensitive':\"Llama-3.1-8B (S)\",\n",
    "                'mistralai_neutral':\"Ministral-8B (NS)\",\n",
    "                'mistralai_sensitive':\"Ministral-8B (S)\",\n",
    "                'Qwen_neutral': \"Qwen2.5-7B (NS)\",\n",
    "                'Qwen_sensitive': \"Qwen2.5-7B (S)\",\n",
    "                'THUDM_neutral': \"GLM-4-9B (NS)\",\n",
    "                'THUDM_sensitive': \"GLM-4-9B (S)\", \n",
    "               }\n",
    "\n",
    "\n",
    "utils = Utils()\n",
    "fairness = Fairness()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing ml-1m, meta-llama_neutral\n",
      "Doing ml-1m, meta-llama_sensitive\n",
      "Doing ml-1m, mistralai_neutral\n",
      "Doing ml-1m, mistralai_sensitive\n",
      "Doing ml-1m, Qwen_neutral\n",
      "Doing ml-1m, Qwen_sensitive\n",
      "Doing ml-1m, THUDM_neutral\n",
      "Doing ml-1m, THUDM_sensitive\n",
      "Doing jobrec, meta-llama_neutral\n",
      "Doing jobrec, meta-llama_sensitive\n",
      "Doing jobrec, mistralai_neutral\n",
      "Doing jobrec, mistralai_sensitive\n",
      "Doing jobrec, Qwen_neutral\n",
      "Doing jobrec, Qwen_sensitive\n",
      "Doing jobrec, THUDM_neutral\n",
      "Doing jobrec, THUDM_sensitive\n",
      "Doing lfm-1b, meta-llama_neutral\n",
      "Doing lfm-1b, meta-llama_sensitive\n",
      "Doing lfm-1b, mistralai_neutral\n",
      "Doing lfm-1b, mistralai_sensitive\n",
      "Doing lfm-1b, Qwen_neutral\n",
      "Doing lfm-1b, Qwen_sensitive\n",
      "Doing lfm-1b, THUDM_neutral\n",
      "Doing lfm-1b, THUDM_sensitive\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "for data in list_data:\n",
    "    df_user = utils.load_df_user(data)\n",
    "    sensitive_cols = df_user.columns[1:].to_list()\n",
    "\n",
    "    df_user = df_user.sort_values(\"user_id\")\n",
    "    df_user.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    per_user_results = glob(f\"../results_llm/{data}*-result*\")\n",
    "\n",
    "    for res in per_user_results:\n",
    "        splitted_name = res.split(\"\\\\\")[1]\n",
    "        _, model, prompt_type, _ = splitted_name.split(\"_\")\n",
    "        model = f\"{model}_{prompt_type}\"\n",
    "\n",
    "        print(f\"Doing {data}, {model}\")\n",
    "        res = pd.read_pickle(res)\n",
    "\n",
    "        df_res = pd.DataFrame(res)\n",
    "        df_res.drop(columns=[\"most_sim_items\"], inplace=True)\n",
    "\n",
    "        df_user = pd.merge(df_user, df_res, left_index=True, right_index=True)\n",
    "\n",
    "\n",
    "        df_user = df_user.rename(columns={\n",
    "                                        \"hit@k\":\"HR\",\n",
    "                                          \"precision@k\":\"P\",\n",
    "                                          \"ndcg@k\":\"NDCG\"\n",
    "                                          })\n",
    "\n",
    "\n",
    "        df_user[\"MRR\"] = df_user.rel.apply(lambda x: 1 / (x.index(1)+1) if 1 in x else 0)\n",
    "\n",
    "        df_user.drop(columns=\"rel\", inplace=True)\n",
    "\n",
    "        # commented out to prefer overwriting the file\n",
    "        # df_user.to_csv(f\"per_user_score/{data}_{model}.csv\", index=False)\n",
    "\n",
    "\n",
    "        if data not in results:\n",
    "            results[data] = OrderedDict()\n",
    "            results[data][model] = OrderedDict()\n",
    "\n",
    "        if model not in results[data]:\n",
    "            results[data][model] = OrderedDict()\n",
    "\n",
    "        \n",
    "        results[data][model][\"HR\"] = df_user.HR.mean()\n",
    "        results[data][model][\"MRR\"] = df_user.MRR.mean()\n",
    "        results[data][model][\"P\"] = df_user.P.mean()\n",
    "        results[data][model][\"NDCG\"] = df_user.NDCG.mean()\n",
    "\n",
    "        for base_score in [\"P\", \"NDCG\"]:\n",
    "\n",
    "            # === GROUP FAIRNESS ===\n",
    "\n",
    "            #1 attrib at a time\n",
    "            for col in sensitive_cols: \n",
    "                selected_cols = [col, base_score]\n",
    "\n",
    "                cleaned_col = utils.clean_col(col)\n",
    "\n",
    "                compute_group_scores(results, data, model, df_user, selected_cols, [col], base_score, agg_type=cleaned_col+\"-\", fairness=fairness)\n",
    "\n",
    "            for i, col1 in enumerate(sensitive_cols[:-1]):\n",
    "                for j, col2 in enumerate(sensitive_cols[i+1:]):\n",
    "                    if col1==col2:\n",
    "                        continue\n",
    "                    selected_cols = [col1, col2, base_score]\n",
    "                    selected_sens = [col1, col2]\n",
    "\n",
    "                    cleaned_cols = [utils.clean_col(col) for col in selected_sens]\n",
    "                    agg_type = \"-\".join(cleaned_cols)\n",
    "                    compute_group_scores(results, data, model, df_user, selected_cols, selected_sens, base_score, agg_type=agg_type+\"-\", fairness=fairness)\n",
    "\n",
    "\n",
    "            selected_cols = sensitive_cols+[base_score]\n",
    "            per_group_score, per_group_count, atk_b, atk_within = compute_group_scores(results, data, model, df_user, selected_cols, sensitive_cols, base_score, fairness=fairness)\n",
    "\n",
    "\n",
    "            # === INDIVIDUAL FAIRNESS ===\n",
    "            results[data][model][f\"SD-Ind-{base_score}\"] = fairness.score_std(df_user[base_score])\n",
    "            results[data][model][f\"Gini-Ind-{base_score}\"] = fairness.gini(df_user[base_score])\n",
    "            results[data][model][f\"Atk-Ind-{base_score}\"]= fairness.atk(df_user[base_score])\n",
    "            results[data][model][f\"DecAtk-Ind-{base_score}\"]= atk_within + atk_b - atk_within*atk_b\n",
    "\n",
    "        df_user.drop(columns=[\"HR\", \"MRR\", \"NDCG\", \"P\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big table LLM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(pd.Series(utils.flatten_dict(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_order = ['HR', 'MRR', 'P', 'NDCG', \n",
    "                 'Min-P', 'Min-NDCG',\n",
    "                 'Range-P',  'Range-NDCG',\n",
    "                 'SD-P',   'SD-NDCG', \n",
    "                 'MAD-P', 'MAD-NDCG',\n",
    "                 'Gini-P', 'Gini-NDCG', \n",
    "                'Atk-P', 'Atk-NDCG',\n",
    "                 'CV-P',  'CV-NDCG',\n",
    "                'FStat-P',  'FStat-NDCG',\n",
    "                'KL-P', 'KL-NDCG',\n",
    "                'GCE-P', 'GCE-NDCG',\n",
    "                'SD-Ind-P', 'SD-Ind-NDCG',\n",
    "                'Gini-Ind-P', 'Gini-Ind-NDCG',\n",
    "                'Atk-Ind-P', 'Atk-Ind-NDCG',\n",
    "                'DecAtk-Ind-P', 'DecAtk-Ind-NDCG',\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_index(indices):\n",
    "    indices = \"\\\\rotatebox[origin=c]{90}{\" + indices + \"}\"\n",
    "    return indices\n",
    "\n",
    "def add_arrows_and_sort(big_table):\n",
    "\n",
    "    lower_is_better = \"Range|SD|Gini|CV|FStat|Atk|MAD|KL|GCE\"\n",
    "    #higher_better = hr, p, ndcg, worst\n",
    "\n",
    "    measure_name = big_table.index.get_level_values(2)\n",
    "    mask_lower = measure_name.str.contains(lower_is_better)\n",
    "    true_order = pd.concat([\n",
    "                        pd.Series(np.where(~mask_lower)[0]),\n",
    "                        pd.Series(np.where(mask_lower)[0]),\n",
    "                        ])\n",
    "    measure_with_arrow = pd.concat([\n",
    "                    pd.Series(\"$\\\\uparrow$ \" + measure_name[~mask_lower]),\n",
    "                    pd.Series(\"$\\downarrow$ \" + measure_name[mask_lower]),\n",
    "                    ])\n",
    "    helper = pd.DataFrame([true_order.reset_index(drop=True),measure_with_arrow.reset_index(drop=True)], index=[\"true_order\", \"measure\"]).T.sort_values(\"true_order\")\n",
    "    big_table = big_table.set_index([big_table.index.get_level_values(0),\n",
    "                                     big_table.index.get_level_values(1),\n",
    "                                     helper.measure.reset_index(drop=True)])\n",
    "    big_table.columns.name = None\n",
    "\n",
    "    return big_table\n",
    "\n",
    "\n",
    "def get_measure_type(index):\n",
    "    pattern = [\"Ind\", \" HR| P| NDCG| MRR\"]\n",
    "    index[(~index.str.contains(pattern[0], regex=True)) & (~index.str.contains(pattern[1], regex=True))] = \"\\\\textsc{Fair (Grp.)}\"\n",
    "    index[index.str.contains(pattern[0], regex=True)] = \"\\\\textsc{Fair (Ind.)}\"\n",
    "    index[index.str.contains(pattern[1], regex=True)] = \"\\\\textsc{Eff}\"\n",
    "    \n",
    "    return index.values\n",
    "\n",
    "def add_measure_type_sort_col(big_table):\n",
    "\n",
    "    index_series = big_table.index\\\n",
    "                                .get_level_values(2)\\\n",
    "                                .to_series()\n",
    "                            \n",
    "    big_table[\"measure_type\"] = get_measure_type(index_series)\n",
    "    big_table[\"measure_type\"] = big_table[\"measure_type\"].apply(rotate_index)\n",
    "    big_table = big_table\\\n",
    "                        .set_index([\"measure_type\"], append=True)\\\n",
    "                        .reorder_levels([1, 0, 3, 2])\n",
    "    big_table.index.names = [None, None, None, None]\n",
    "\n",
    "    return big_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consists of different ways of grouping (only 1 attribute, 2 attributes, and all 3 attributes)\n",
    "big_table_full = add_arrows_and_sort(df_results)\n",
    "big_table_full = big_table_full\\\n",
    "                        .unstack([0])\\\n",
    "                        .droplevel(0, axis=1)\n",
    "\n",
    "#save here\n",
    "timenow = utils.timenow()\n",
    "big_table_full.to_csv(f\"multiple_groups/multiple_groups_LLM_{timenow}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df_results = df_results.reindex(measure_order, level=2)\n",
    "df_result_arrow = add_arrows_and_sort(sorted_df_results)\n",
    "df_result_arrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">ml-1m</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">meta-llama_neutral</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">\\rotatebox[origin=c]{90}{\\textsc{Eff}}</th>\n",
       "      <th>$\\uparrow$ HR</th>\n",
       "      <td>0.259677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\uparrow$ MRR</th>\n",
       "      <td>0.101489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\uparrow$ P</th>\n",
       "      <td>0.045968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\uparrow$ NDCG</th>\n",
       "      <td>0.139983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\rotatebox[origin=c]{90}{\\textsc{Fair (Grp.)}}</th>\n",
       "      <th>$\\uparrow$ Min-P</th>\n",
       "      <td>0.030357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">lfm-1b</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">THUDM_sensitive</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">\\rotatebox[origin=c]{90}{\\textsc{Fair (Ind.)}}</th>\n",
       "      <th>$\\downarrow$ Gini-Ind-NDCG</th>\n",
       "      <td>0.460593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\downarrow$ Atk-Ind-P</th>\n",
       "      <td>0.411271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\downarrow$ Atk-Ind-NDCG</th>\n",
       "      <td>0.357888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\downarrow$ DecAtk-Ind-P</th>\n",
       "      <td>0.411271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$\\downarrow$ DecAtk-Ind-NDCG</th>\n",
       "      <td>0.357888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                              0\n",
       "ml-1m  meta-llama_neutral \\rotatebox[origin=c]{90}{\\textsc{Eff}}         $\\uparrow$ HR                 0.259677\n",
       "                                                                         $\\uparrow$ MRR                0.101489\n",
       "                                                                         $\\uparrow$ P                  0.045968\n",
       "                                                                         $\\uparrow$ NDCG               0.139983\n",
       "                          \\rotatebox[origin=c]{90}{\\textsc{Fair (Grp.)}} $\\uparrow$ Min-P              0.030357\n",
       "...                                                                                                         ...\n",
       "lfm-1b THUDM_sensitive    \\rotatebox[origin=c]{90}{\\textsc{Fair (Ind.)}} $\\downarrow$ Gini-Ind-NDCG    0.460593\n",
       "                                                                         $\\downarrow$ Atk-Ind-P        0.411271\n",
       "                                                                         $\\downarrow$ Atk-Ind-NDCG     0.357888\n",
       "                                                                         $\\downarrow$ DecAtk-Ind-P     0.411271\n",
       "                                                                         $\\downarrow$ DecAtk-Ind-NDCG  0.357888\n",
       "\n",
       "[768 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result_measure_type = add_measure_type_sort_col(df_result_arrow)\n",
    "df_result_measure_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = df_result_arrow.index.get_level_values(2).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['meta-llama_neutral',\n",
       " 'meta-llama_sensitive',\n",
       " 'mistralai_neutral',\n",
       " 'mistralai_sensitive',\n",
       " 'Qwen_neutral',\n",
       " 'Qwen_sensitive',\n",
       " 'THUDM_neutral',\n",
       " 'THUDM_sensitive']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result_measure_type.index.get_level_values(1).unique().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save results here, so we can do corr analysis in another notebook\n",
    "\n",
    "big_table_for_save =  df_result_measure_type\\\n",
    "                .unstack([1])\\\n",
    "                .droplevel(0, axis=1)\\\n",
    "                .loc[[\"ml-1m\", \"jobrec\", \"lfm-1b\"]]\\\n",
    "                .rename(columns=map_columns, index=map_columns)\\\n",
    "                .reindex(order, level=2)\n",
    "\n",
    "# timenow = utils.timenow()\n",
    "# big_table_for_save.to_csv(f\"table/big_table_LLM_{timenow}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "big_table = df_result_measure_type\\\n",
    "                .unstack([0,1])\\\n",
    "                .droplevel(0, axis=1)\\\n",
    "                .loc[:,[\"ml-1m\", \"jobrec\", \"lfm-1b\"]]\\\n",
    "                .rename(columns=map_columns)\\\n",
    "                .reindex(order, level=1)\\\n",
    "                .round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_table.index = big_table.index.set_levels(big_table.index.levels[1].str.replace(\"Ind-\",\"\\-\"), level=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate into P and NDCG table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_separate = big_table.reset_index(level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_table_p = to_separate.loc[to_separate[\"level_1\"].str.contains(\"-P| HR| MRR| P\")]\n",
    "big_table_ndcg = to_separate.loc[to_separate[\"level_1\"].str.contains(\"-NDCG| HR| MRR| NDCG\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_table_p = big_table_p.set_index(\"level_1\", append=True)\n",
    "big_table_ndcg = big_table_ndcg.set_index(\"level_1\", append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_table_p.index.names = [None, None]\n",
    "big_table_ndcg.index.names = [None, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_p = df_result_arrow.index.get_level_values(2)[df_result_arrow.index.get_level_values(2).str.contains(\" HR| MRR| P|-P\")].str.replace(\"Ind-\",\"\\-\").unique()\n",
    "order_ndcg = df_result_arrow.index.get_level_values(2)[df_result_arrow.index.get_level_values(2).str.contains(\" HR| MRR| NDCG|-NDCG\")].str.replace(\"Ind-\",\"\\-\").unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model type and prompt type\n",
    "def separate_model_and_prompt(df, order):\n",
    "    df = df.stack(1)\n",
    "\n",
    "\n",
    "    new_index = np.asarray(\n",
    "                        df.index\\\n",
    "                            .get_level_values(2)\\\n",
    "                            .str.replace(\"[()]\",\"\", regex=True)\\\n",
    "                            .str.split(\" \")\\\n",
    "                            .tolist())\\\n",
    "                            .T\n",
    "\n",
    "    df = df.set_index(pd.MultiIndex.from_arrays(new_index), append=True)\n",
    "    df = df.droplevel(2)\n",
    "    df = df.unstack([2,3])\n",
    "    df = df.reindex(order, level=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_table_p = separate_model_and_prompt(big_table_p, order_p)\n",
    "big_table_ndcg = separate_model_and_prompt(big_table_ndcg, order_ndcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "list_data_proper = [\"ML-1M\", \"JobRec\", \"LFM-1B\"]\n",
    "\n",
    "col = sns.light_palette(\"seagreen\").as_hex()[4]\n",
    "\n",
    "def highlight_max(x):\n",
    "    return np.where(x == np.nanmax(x.to_numpy()), f\"font-weight: bold;\", None)\n",
    "\n",
    "def highlight_min(x):\n",
    "    return np.where(x == np.nanmin(x.to_numpy()), f\"font-weight: bold;\", None)\n",
    "\n",
    "def add_cdashline(measure, latex_code, df):\n",
    "    end_index = []\n",
    "    for el in re.finditer(f\"{measure}.*\\\\n\",latex_code):\n",
    "        end_index.append(el.end())\n",
    "    j = df[[\"ML-1M\"]].shape[1] + 2\n",
    "    for idx in reversed(end_index):\n",
    "        latex_code= latex_code[:idx] + \"\\\\cdashline{2-\" + str(j) + \"}\\n\" + latex_code[idx:]\n",
    "    return latex_code\n",
    "\n",
    "\n",
    "def nicetable(df, color=False):\n",
    "\n",
    "    the_index = df.index.levels[1]\n",
    "\n",
    "    row_with_up = the_index[the_index.str.contains(\"uparrow\")]\n",
    "    row_with_down = the_index[the_index.str.contains(\"downarrow\")]\n",
    "\n",
    "    idx = pd.IndexSlice\n",
    "\n",
    "    for data in df.columns.levels[0]:\n",
    "\n",
    "        styler = df[[data]].style\n",
    "        styler.format(formatter=\"{:.3f}\")\n",
    "\n",
    "        slice_max = idx[idx[:, row_with_up], :]\n",
    "        slice_min = idx[idx[:,row_with_down],:]\n",
    "\n",
    "        styler\\\n",
    "            .apply(highlight_max, axis=1, subset=slice_max)\\\n",
    "            .apply(highlight_min, axis=1, subset=slice_min)\n",
    "\n",
    "        if color:\n",
    "            cm = sns.light_palette(col, as_cmap=True)\n",
    "            cm_r = sns.light_palette(col, reverse=True, as_cmap=True)\n",
    "            styler\\\n",
    "                .background_gradient(cmap=cm, axis=1,  subset=slice_max)\\\n",
    "                .background_gradient(cmap=cm_r, axis=1, subset=slice_min)\\\n",
    "\n",
    "        latex_code = styler.to_latex(\n",
    "            hrules=True, \n",
    "            clines=\"skip-last;data\",\n",
    "            convert_css=True, \n",
    "            column_format = \"ll*{2}{r}|*{2}{r}|*{2}{r}|*{2}{r}\",\n",
    "            multicol_align = \"c|\"\n",
    "            )\n",
    "\n",
    "        # erase last cline\n",
    "        last_cline_starts = latex_code.find(\"\\\\cline\", -100,-1)\n",
    "        last_cline_ends = latex_code.find(\"\\\\bottomrule\")\n",
    "        latex_code = latex_code[:last_cline_starts] + latex_code[last_cline_ends:]\n",
    "\n",
    "        latex_code = add_cdashline(\"Atk\\-(P|N)\", latex_code, df)\n",
    "        \n",
    "        latex_code = latex_code.replace(\"\\\\begin{tabular}\",\"\\\\resizebox{0.98\\columnwidth}{!}{\\n\\\\begin{tabular}\") #add resize box\n",
    "        latex_code = latex_code.replace(\"{c|}{\"+data+\"} \\\\\\\\\", \"{c}{\"+data+\"} \\\\\\\\ \\n\\midrule\") #add midrule after k and get rid of last |\n",
    "        latex_code = latex_code.replace(\"{c|}{Qwen2.5-7B} \\\\\\\\\", \"{c}{Qwen2.5-7B} \\\\\\\\ \\n\\midrule\") #add midrule after k and get rid of last |\n",
    "        latex_code = latex_code.replace(\"\\end{tabular}\",\"\\end{tabular}}\") #add } as part of resize box\n",
    "        latex_code = latex_code.replace(\"\\t\",\"\\\\t\")\n",
    "\n",
    "        latex_code = latex_code.replace(\"-P\",\"\")\n",
    "        latex_code = latex_code.replace(\"-NDCG\",\"\")\n",
    "        latex_code = latex_code.replace(\"-\\\\\",\"\")\n",
    "        latex_code = latex_code.replace(\"\\color[HTML]{F1F1F1}\",\"\")\n",
    "        latex_code = latex_code.replace(\"\\color[HTML]{000000}\",\"\")\n",
    "\n",
    "        print(latex_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nicetable(big_table_p[list_data_proper], color=True)\n",
    "nicetable(big_table_ndcg[list_data_proper], color=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple ways of grouping table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import measure_type_multiple_group, fill_attr, print_group_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "list_data_proper = [\"ML-1M\", \"JobRec\", \"LFM-1B\"]\n",
    "latest_file = sorted(glob(\"multiple_groups/multiple_groups_LLM_*.csv\"))[-1]\n",
    "# Load the latest file\n",
    "print(f\"Loading latest file: {latest_file}\")\n",
    "big_table_full = pd.read_csv(latest_file, index_col=[0,1])\n",
    "big_table_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>measure</th>\n",
       "      <th>THUDM_neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jobrec</td>\n",
       "      <td>$\\downarrow$ Atk-Degree-Experience-NDCG</td>\n",
       "      <td>0.163747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jobrec</td>\n",
       "      <td>$\\downarrow$ Atk-Degree-Major-NDCG</td>\n",
       "      <td>0.253214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jobrec</td>\n",
       "      <td>$\\downarrow$ Atk-Degree-NDCG</td>\n",
       "      <td>0.007456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>jobrec</td>\n",
       "      <td>$\\downarrow$ Atk-Experience-Major-NDCG</td>\n",
       "      <td>0.412942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>jobrec</td>\n",
       "      <td>$\\downarrow$ Atk-Experience-NDCG</td>\n",
       "      <td>0.026185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>ml-1m</td>\n",
       "      <td>$\\downarrow$ SD-Within-Gender-Age-NDCG</td>\n",
       "      <td>0.329302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>ml-1m</td>\n",
       "      <td>$\\downarrow$ SD-Within-Gender-NDCG</td>\n",
       "      <td>0.329577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>ml-1m</td>\n",
       "      <td>$\\downarrow$ SD-Within-Gender-Occupation-NDCG</td>\n",
       "      <td>0.329850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>ml-1m</td>\n",
       "      <td>$\\downarrow$ SD-Within-NDCG</td>\n",
       "      <td>0.329207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>ml-1m</td>\n",
       "      <td>$\\downarrow$ SD-Within-Occupation-NDCG</td>\n",
       "      <td>0.329519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>135 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    dataset                                        measure  THUDM_neutral\n",
       "0    jobrec        $\\downarrow$ Atk-Degree-Experience-NDCG       0.163747\n",
       "2    jobrec             $\\downarrow$ Atk-Degree-Major-NDCG       0.253214\n",
       "4    jobrec                   $\\downarrow$ Atk-Degree-NDCG       0.007456\n",
       "6    jobrec         $\\downarrow$ Atk-Experience-Major-NDCG       0.412942\n",
       "8    jobrec               $\\downarrow$ Atk-Experience-NDCG       0.026185\n",
       "..      ...                                            ...            ...\n",
       "554   ml-1m         $\\downarrow$ SD-Within-Gender-Age-NDCG       0.329302\n",
       "556   ml-1m             $\\downarrow$ SD-Within-Gender-NDCG       0.329577\n",
       "557   ml-1m  $\\downarrow$ SD-Within-Gender-Occupation-NDCG       0.329850\n",
       "560   ml-1m                    $\\downarrow$ SD-Within-NDCG       0.329207\n",
       "561   ml-1m         $\\downarrow$ SD-Within-Occupation-NDCG       0.329519\n",
       "\n",
       "[135 rows x 3 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_model = \"THUDM_neutral\"\n",
    "selected_agg = \"SD|Gini|Atk\"\n",
    "selected_base = \"-NDCG\"\n",
    "excluded = \"Dec\" #decomposed Atk\n",
    "\n",
    "df_group = big_table_full[selected_model].reset_index().rename(columns={\"level_0\":\"dataset\"})\n",
    "df_group = df_group[df_group.measure.str.contains(selected_agg)]\n",
    "df_group = df_group[df_group.measure.str.contains(selected_base)]\n",
    "df_group = df_group[~df_group.measure.str.contains(excluded)]\n",
    "df_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group[\"measure_type\"] = df_group.measure.apply(measure_type_multiple_group)\n",
    "df_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group[\"group_context\"] = df_group[\"measure\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group[\"measure\"] = df_group[\"measure\"]\\\n",
    "                            .str.replace(\"-Ind|-NDCG\",\"\", regex=True)\\\n",
    "                            .str.replace(\"\\-.*\", \"\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group[\"group_context\"] = df_group[\"group_context\"]\\\n",
    "                                .str.replace(\"-Ind|-NDCG\",\"\", regex=True)\\\n",
    "                                .str.split(\"-\")\\\n",
    "                                .apply(lambda x: [x for x in x if \"arrow\" not in x])\\\n",
    "                                .apply(lambda x: \"-\".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_table = df_group\\\n",
    "                .set_index([\"dataset\", \"measure_type\",\"group_context\",\"measure\"])\\\n",
    "                .reindex([ \"Grp (1)\", \"Grp (2)\",\"Grp (3)\", \"Ind\",], level=1)\\\n",
    "                .unstack(3)\\\n",
    "                .loc[list_data]\n",
    "\n",
    "group_table.index.names = [\"data\", \"Fair\", \"Attr.\"]\n",
    "group_table = group_table.droplevel(level=0, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_table = group_table.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_table_no_within = group_table[~group_table[\"Attr.\"].str.contains(\"Within\")]\n",
    "group_table_within = group_table[(group_table[\"Attr.\"].str.contains(\"Within\"))|(group_table[\"Fair\"].str.contains(\"Ind\"))]\n",
    "group_table_no_within = fill_attr(group_table_no_within)\n",
    "group_table_within = fill_attr(group_table_within)\n",
    "printed_between = print_group_table(group_table_no_within)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_table_within[\"Attr.\"] = group_table_within[\"Attr.\"].str.replace(\"Within-\",\"\")\n",
    "printed_within = print_group_table(group_table_within)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot multiple groups vs Individual fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import prep_df_for_lineplot, plot_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_score = \"NDCG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_min_max_group_count():\n",
    "    curr_min = 999999999999\n",
    "    curr_max = 0\n",
    "    \n",
    "    for col in sensitive_cols: \n",
    "        selected_cols = [col, base_score]\n",
    "\n",
    "        per_group_count = df_user[selected_cols]\\\n",
    "                                .groupby(col)\\\n",
    "                                .count()[base_score]\n",
    "        \n",
    "        per_group_count = per_group_count[per_group_count>0]\n",
    "\n",
    "        num_group = per_group_count.shape[0]\n",
    "\n",
    "        if num_group < curr_min:\n",
    "            curr_min = num_group\n",
    "        if num_group > curr_max:\n",
    "            curr_max = num_group\n",
    "    return curr_min, curr_max\n",
    "\n",
    "def get_min_max_group_count_nested():\n",
    "    curr_min = 999999999999\n",
    "    curr_max = 0\n",
    "\n",
    "    for i, col1 in enumerate(sensitive_cols[:-1]):\n",
    "        for j, col2 in enumerate(sensitive_cols[i+1:]):\n",
    "            if col1==col2:\n",
    "                continue\n",
    "            selected_cols = [col1, col2, base_score]\n",
    "            selected_sens = [col1, col2]\n",
    "\n",
    "\n",
    "            per_group_count = df_user[selected_cols]\\\n",
    "                                .groupby(selected_sens)\\\n",
    "                                .count()[base_score]\n",
    "        \n",
    "            per_group_count = per_group_count[per_group_count>0]\n",
    "\n",
    "            num_group = per_group_count.shape[0]\n",
    "\n",
    "            if num_group < curr_min:\n",
    "                curr_min = num_group\n",
    "            if num_group > curr_max:\n",
    "                curr_max = num_group\n",
    "    return curr_min, curr_max\n",
    "\n",
    "def get_min_max_group_count_all():\n",
    "\n",
    "    selected_cols = sensitive_cols+[base_score]\n",
    "\n",
    "\n",
    "    per_group_count = df_user[selected_cols]\\\n",
    "                        .groupby(sensitive_cols)\\\n",
    "                        .count()[base_score]\n",
    "\n",
    "    per_group_count = per_group_count[per_group_count>0]\n",
    "\n",
    "    num_group = per_group_count.shape[0]\n",
    "\n",
    "    return num_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ml-1m\n",
      "jobrec\n",
      "lfm-1b\n"
     ]
    }
   ],
   "source": [
    "min_max_group = dict()\n",
    "\n",
    "for data in list_data:\n",
    "    print(data)\n",
    "    min_max_group[data] = {}\n",
    "\n",
    "    df_user = pd.read_csv(f\"per_user_score/{data}_Qwen_neutral.csv\")\n",
    "    sensitive_cols = df_user.columns[1:4].to_list()\n",
    "\n",
    "    #1 attrib at a time\n",
    "    curr_min, curr_max = get_min_max_group_count()\n",
    "    min_max_group[data][\"Grp (1)\"] = f\"{curr_min}-{curr_max}\"\n",
    "\n",
    "    #2 attribs at a time\n",
    "    curr_min, curr_max = get_min_max_group_count_nested()\n",
    "    min_max_group[data][\"Grp (2)\"] = f\"{curr_min}-{curr_max}\"\n",
    "\n",
    "    #3 attribs at a time\n",
    "    grp_count = get_min_max_group_count_all()\n",
    "    min_max_group[data][\"Grp (3)\"] = str(grp_count)\n",
    "\n",
    "    min_max_group[data][\"Ind\"] = str(df_user.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# commented out to prefer overwriting the file\n",
    "# with open(f\"group_count_dict.pickle\",\"wb\") as f:\n",
    "#     pickle.dump(min_max_group, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_group = pd.read_pickle(\"group_count_dict.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_group_count(df_group):\n",
    "\n",
    "    df_group.loc[df_group.data==\"ML-1M\", \"Fairness Type\"] = df_group.loc[df_group.data==\"ML-1M\", \"Fairness Type\"].apply(lambda x: x+\"\\n\"+min_max_group[\"ml-1m\"][x])\n",
    "    df_group.loc[df_group.data==\"JobRec\", \"Fairness Type\"] = df_group.loc[df_group.data==\"JobRec\", \"Fairness Type\"].apply(lambda x: x+\"\\n\"+min_max_group[\"jobrec\"][x])\n",
    "    df_group.loc[df_group.data==\"LFM-1B\", \"Fairness Type\"] = df_group.loc[df_group.data==\"LFM-1B\", \"Fairness Type\"].apply(lambda x: x+\"\\n\"+min_max_group[\"lfm-1b\"][x])\n",
    "\n",
    "    return df_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save = False\n",
    "# save = True\n",
    "\n",
    "btw_group = prep_df_for_lineplot(printed_between)\n",
    "wth_group = prep_df_for_lineplot(printed_within)\n",
    "\n",
    "btw_group = map_to_group_count(btw_group)\n",
    "\n",
    "btw_group = btw_group.rename(columns={\"Fairness Type\":\"#groups\"})\n",
    "wth_group = wth_group.rename(columns={\"Fairness Type\":\"#groups\"})\n",
    "\n",
    "plot_line(btw_group, exp_type=\"between_LLM\", save=save)\n",
    "plot_line(wth_group, exp_type=\"within_LLM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_score = \"NDCG\"\n",
    "def get_group_count():\n",
    "    res = dict()   \n",
    "    for col in sensitive_cols: \n",
    "        selected_cols = [col, base_score]\n",
    "\n",
    "        per_group_count = df_user[selected_cols]\\\n",
    "                                .groupby(col)\\\n",
    "                                .count()[base_score]\n",
    "        \n",
    "        per_group_count = per_group_count[per_group_count>0]\n",
    "\n",
    "        num_group = per_group_count.shape[0]\n",
    "        res[utils.clean_col(col)] = num_group\n",
    "\n",
    "    return res\n",
    "\n",
    "def get_group_count_nested():\n",
    "    res = dict()   \n",
    "    for i, col1 in enumerate(sensitive_cols[:-1]):\n",
    "        for j, col2 in enumerate(sensitive_cols[i+1:]):\n",
    "            if col1==col2:\n",
    "                continue\n",
    "            selected_cols = [col1, col2, base_score]\n",
    "            selected_sens = [col1, col2]\n",
    "\n",
    "\n",
    "            per_group_count = df_user[selected_cols]\\\n",
    "                                .groupby(selected_sens)\\\n",
    "                                .count()[base_score]\n",
    "        \n",
    "            per_group_count = per_group_count[per_group_count>0]\n",
    "\n",
    "            num_group = per_group_count.shape[0]\n",
    "            cleaned_col1 = utils.clean_col(col1)\n",
    "            cleaned_col2 = utils.clean_col(col2)\n",
    "            res[f\"{cleaned_col1}-{cleaned_col2}\"] = num_group\n",
    "\n",
    "    return res\n",
    "\n",
    "def get_group_count_all():\n",
    "\n",
    "    selected_cols = sensitive_cols+[base_score]\n",
    "\n",
    "\n",
    "    per_group_count = df_user[selected_cols]\\\n",
    "                        .groupby(sensitive_cols)\\\n",
    "                        .count()[base_score]\n",
    "\n",
    "    per_group_count = per_group_count[per_group_count>0]\n",
    "\n",
    "    num_group = per_group_count.shape[0]\n",
    "\n",
    "    return num_group\n",
    "\n",
    "group_count = dict()\n",
    "\n",
    "for data in list_data:\n",
    "    print(data)\n",
    "    group_count[data] = {}\n",
    "\n",
    "    # doesn't really matter which model we use here, as we only need the user sensitive attributes\n",
    "    df_user = pd.read_csv(f\"per_user_score/{data}_Qwen_neutral.csv\")\n",
    "    sensitive_cols = df_user.columns[1:4].to_list()\n",
    "\n",
    "    #1 attrib at a time\n",
    "    res_dict = get_group_count()\n",
    "    group_count[data] = res_dict\n",
    "\n",
    "    #2 attribs at a time\n",
    "    res_dict = get_group_count_nested()\n",
    "    group_count[data].update(res_dict)\n",
    "\n",
    "    #3 attribs at a time\n",
    "    grp_count = get_group_count_all()\n",
    "\n",
    "    cleaned_sens_col = [utils.clean_col(col) for col in sensitive_cols]\n",
    "\n",
    "    group_count[data][\"-\".join(cleaned_sens_col)] = grp_count\n",
    "\n",
    "    group_count[data][\"Ind\"] = df_user.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_group_count_fine(df_group):\n",
    "\n",
    "    df_group[\"num\"] = pd.Series()\n",
    "    df_group.loc[df_group.data==\"ML-1M\", \"num\"] = df_group.loc[df_group.data==\"ML-1M\", \"Attr.\"].apply(lambda x: group_count[\"ml-1m\"][x] if x!=\"-\" else group_count[\"ml-1m\"][\"Ind\"])\n",
    "    df_group.loc[df_group.data==\"JobRec\", \"num\"] = df_group.loc[df_group.data==\"JobRec\", \"Attr.\"].apply(lambda x: group_count[\"jobrec\"][x] if x!=\"-\" else group_count[\"jobrec\"][\"Ind\"])\n",
    "    df_group.loc[df_group.data==\"LFM-1B\", \"num\"] = df_group.loc[df_group.data==\"LFM-1B\", \"Attr.\"].apply(lambda x: group_count[\"lfm-1b\"][x] if x!=\"-\" else group_count[\"lfm-1b\"][\"Ind\"])\n",
    "\n",
    "    return df_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn.objects as so\n",
    "btw_group[\"component\"] = \"between\"\n",
    "wth_group[\"component\"] =  \"within\"\n",
    "\n",
    "btw_group = map_to_group_count_fine(btw_group)\n",
    "wth_group = map_to_group_count_fine(wth_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_and_add_name(df):\n",
    "    map_data = {\"ML-1M\":1, \"JobRec\":2, \"LFM-1B\":3}\n",
    "    df[\"data_idx\"] = df[\"data\"].map(map_data)\n",
    "\n",
    "    df.sort_values([\"data_idx\",\"num\"], inplace=True, kind=\"stable\")\n",
    "    df[\"Attr.\"] = df[\"Attr.\"] + \"\\n(\" +df[\"num\"].astype(str) + \")\"\n",
    "    df[\"Attr.\"] = df[\"Attr.\"].str.replace(\"-\", \"\\n\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "btw_group = sort_and_add_name(btw_group)\n",
    "wth_group = sort_and_add_name(wth_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.ticker as ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in list_data_proper:\n",
    "    selected_btw = btw_group.query(\"data==@data\")\n",
    "    selected_wth = wth_group.query(\"data==@data\")\n",
    "    btw_no_ind = selected_btw[~selected_btw[\"#groups\"].str.contains(\"Ind\")]\n",
    "    wth_no_ind = selected_wth[~selected_wth[\"#groups\"].str.contains(\"Ind\")]\n",
    "\n",
    "    btw_no_ind[\"Attr.\"] = btw_no_ind[\"Attr.\"].str.replace(\"Continent\",\"Country\")\n",
    "    wth_no_ind[\"Attr.\"] = wth_no_ind[\"Attr.\"].str.replace(\"Continent\",\"Country\")\n",
    "\n",
    "\n",
    "    blue_patch = mpatches.Patch(color=sns.color_palette(\"colorblind\")[0], label='The blue data')\n",
    "    orange_patch = mpatches.Patch(color=sns.color_palette(\"colorblind\")[1], label='The orange data')\n",
    "\n",
    "    #handle for individual fairness\n",
    "    dotted_line = mlines.Line2D([], [], color='black', linestyle=\"--\", label=\"dotted_line\")\n",
    "\n",
    "    #placeholder handle for unfairness\n",
    "    fake = mlines.Line2D([], [], color='white', linestyle=\"--\", label=\"dotted_line\")\n",
    "\n",
    "    f = plt.figure(figsize=(7,3.75))\n",
    "    f.set_layout_engine(\"constrained\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "\n",
    "    legend = plt.legend(labels=[\"Unfairness\", \"between-group\", \"within-group\", \"individual\"], handles=[fake, blue_patch, orange_patch, dotted_line], \n",
    "            loc=\"upper center\",\n",
    "            bbox_to_anchor=(0.55, 1.585),\n",
    "            ncols=4,\n",
    "            )\n",
    "    p = so.Plot(pd.concat(\n",
    "                        [btw_no_ind,\n",
    "                        wth_no_ind\n",
    "                        ]), \n",
    "                \n",
    "                        x=\"Attr.\", y=f\"$\\downarrow$Unfairness\", \n",
    "                        color=\"component\"\n",
    "                        )\\\n",
    "                        .facet(row=\"measure\")\\\n",
    "                        .add(so.Bar(), so.Agg(\"mean\"), so.Dodge(), legend=False)\\\n",
    "                        .layout(size=(9, 9))\\\n",
    "                        .share(x=True, y=False)\\\n",
    "                        .scale(color=\"colorblind\")\\\n",
    "                        .on(f).plot()\n",
    "\n",
    "\n",
    "    list_measures = [\"SD\", \"Gini\", \"Atk\"]\n",
    "    for i in range(1, 4):\n",
    "        ax = f.axes[i]\n",
    "        measure = list_measures[i-1]\n",
    "        y_val = selected_btw[selected_btw[\"#groups\"].str.contains(\"Ind\")]\\\n",
    "                                                                        .query(\"measure==@measure\")[\"$\\downarrow$Unfairness\"]\\\n",
    "                                                                        .values[0]\n",
    "\n",
    "        #plot Ind as line instead\n",
    "        ax.axhline(y=y_val, color='black', linestyle='--', alpha=0.75, linewidth=0.75)\n",
    "\n",
    "    # change x axis name \n",
    "    ax.set_xlabel(\"Group \\n(#groups)\")\n",
    "\n",
    "\n",
    "    for ax in f.axes:\n",
    "        ax.set_ylabel(\"$\\\\downarrow$\"+ax.get_title())\n",
    "        ax.yaxis.label.set_size(fontsize=10)\n",
    "        ax.xaxis.label.set_size(fontsize=10)\n",
    "        ax.set_title(\"\")\n",
    "        ax.yaxis.set_major_locator(ticker.MaxNLocator(nbins=4))\n",
    "        ax.xaxis.set_label_coords(-0.05, -0.19)\n",
    "\n",
    "    f.axes[1].set_title(data)\n",
    "    time = utils.timenow()\n",
    "\n",
    "    plt.savefig(f'multiple_groups/temp_{time}_decomposability_all_{data}.pdf', bbox_inches='tight')\n",
    "    p.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agreement of different ways of grouping and individual fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_agg = \"SD|Gini|Atk\"\n",
    "selected_base = \"-NDCG\"\n",
    "excluded = \"Dec|Within\" #decomposed Atk\n",
    "\n",
    "\n",
    "df_group_all = big_table_full.reset_index().rename(columns={\"level_0\":\"dataset\"})\n",
    "df_group_all = df_group_all[df_group_all.measure.str.contains(selected_agg)]\n",
    "df_group_all = df_group_all[df_group_all.measure.str.contains(selected_base)]\n",
    "df_group_all = df_group_all[~df_group_all.measure.str.contains(excluded)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group_all[\"measure_type\"] = df_group_all.measure.apply(measure_type_multiple_group)\n",
    "df_group_all[\"group_context\"] = df_group_all[\"measure\"].copy()\n",
    "df_group_all[\"measure\"] = df_group_all[\"measure\"]\\\n",
    "                            .str.replace(\"-Ind|-NDCG\",\"\", regex=True)\\\n",
    "                            .str.replace(\"\\-.*\", \"\", regex=True)\n",
    "df_group_all[\"group_context\"] = df_group_all[\"group_context\"]\\\n",
    "                                .str.replace(\"-Ind|-NDCG\",\"\", regex=True)\\\n",
    "                                .str.split(\"-\")\\\n",
    "                                .apply(lambda x: [x for x in x if \"arrow\" not in x])\\\n",
    "                                .apply(lambda x: \"-\".join(x))\n",
    "\n",
    "group_table = df_group_all\\\n",
    "                .set_index([\"dataset\", \"measure_type\",\"group_context\",\"measure\"])\\\n",
    "                .reindex([ \"Grp (1)\", \"Grp (2)\",\"Grp (3)\", \"Ind\",], level=1)\\\n",
    "                .unstack(3)\\\n",
    "                .loc[list_data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_measure = [\"$\\downarrow$ SD\", \"$\\downarrow$ Gini\", \"$\\downarrow$ Atk\"]\n",
    "\n",
    "hm_kws = dict(annot=True, #square=True, \n",
    "              vmin=-1, vmax=1, \n",
    "                   cmap=\"coolwarm_r\", annot_kws={\"size\": 11},  \n",
    "                cbar_kws={\"orientation\": \"horizontal\"})\n",
    "\n",
    "fig, ax = plt.subplots(ncols=len(list_data),\n",
    "                       figsize=(8,3.75)\n",
    "                       )\n",
    "\n",
    "cbar_ax = fig.add_axes([.25, -.03, .7, .025])\n",
    "cbar_ax.tick_params(labelsize=9)\n",
    "\n",
    "for i, (ax_id, data) in enumerate(zip(ax, list_data)):\n",
    "    df_agreement = pd.DataFrame()\n",
    "    for meas in list_measure:\n",
    "        df_this_meas = df_group_all\\\n",
    "                            .set_index([\"dataset\", \"measure_type\",\"group_context\",\"measure\"])\\\n",
    "                            .reindex([ \"Grp (1)\", \"Grp (2)\",\"Grp (3)\", \"Ind\",], level=1)\\\n",
    "                            .swaplevel(1,3, axis=0)\\\n",
    "                            .swaplevel(2,3, axis=0)\\\n",
    "                            .loc[data].T.corr(\"kendall\")\\\n",
    "                            .round(2)\\\n",
    "                            .loc[meas].loc[\"Ind\"].loc[:, meas]\n",
    "        \n",
    "        df_this_meas[\"measure\"] = meas.split(\" \")[-1]\n",
    "\n",
    "        if len(df_agreement) == 0:\n",
    "            df_agreement = df_this_meas\n",
    "        else:\n",
    "            df_agreement = pd.concat([df_agreement, df_this_meas])\n",
    "\n",
    "    df_agreement = df_agreement.set_index(\"measure\") \n",
    "    df_agreement = df_agreement.droplevel(level=0, axis=1)\n",
    "    \n",
    "    # remove individual fairness corr with itself\n",
    "    df_agreement = df_agreement.iloc[:,:-1].T\n",
    "\n",
    "    # change last index to \"All\"\n",
    "    idx_name =  df_agreement.index.to_list() \n",
    "    idx_name[-1] = \"All\"\n",
    "    df_agreement.index = idx_name\n",
    "    df_agreement.index = df_agreement.index.str.replace(\"-\", \"\\n\")\n",
    "\n",
    "    index_order = pd.Series(group_count[data]).sort_values()[:-1].index\n",
    "    index_order = index_order.str.replace(\"-\", \"\\n\").to_list()\n",
    "    index_order[-1] = \"All\"\n",
    "\n",
    "    df_agreement = df_agreement.reindex(index_order)\n",
    "    df_agreement.index = df_agreement.index.str.replace(\"Continent\",\"Country\")\n",
    "                \n",
    "    hm = sns.heatmap(df_agreement, ax=ax_id, cbar=i==0, \n",
    "                        cbar_ax=None if i else cbar_ax,\n",
    "                     **hm_kws)\n",
    "\n",
    "    ax_id.set_title(map_columns[data])\n",
    "    if data != \"lfm-1b\":\n",
    "        hm.set_ylabel(None)\n",
    "    else:\n",
    "        hm.set_ylabel(\"$Group\\ fairness$\", rotation=270,loc=\"center\",labelpad=10, fontsize=11)\n",
    "        ax_id.yaxis.set_label_position(\"right\")\n",
    "\n",
    "    hm.set_xlabel(\"$Individual\\ fairness$\", rotation=0, fontsize=11)\n",
    "    ax_id.set_yticklabels(ax_id.get_yticklabels(), rotation=0, fontsize=11)\n",
    "    ax_id.set_xticklabels(ax_id.get_xticklabels(), rotation=0, fontsize=11)\n",
    "\n",
    "horiz_start_end = (0.1, 0.968)\n",
    "height = 0.58\n",
    "line_kw = dict(xdata=horiz_start_end,\n",
    "                ls=\"--\", color=\"#1A224C\",\n",
    "                               transform=fig.transFigure)\n",
    "\n",
    "line = Line2D( ydata=(height, height),**line_kw)\n",
    "height = 0.26\n",
    "line2 = Line2D( ydata=(height, height),**line_kw)\n",
    "\n",
    "height = 0.9\n",
    "line0 = Line2D( ydata=(height, height),**line_kw)\n",
    "\n",
    "height = 0.16\n",
    "line3 = Line2D( ydata=(height, height),**line_kw)\n",
    "\n",
    "fig.lines = line,line2,line0, line3\n",
    "\n",
    "args = {\"clip_on\":False,\"size\":10}\n",
    "\n",
    "ax[0].text(-2.5, 0, '#Attributes',\n",
    "    horizontalalignment='left',\n",
    "    verticalalignment='bottom',\n",
    "    weight=\"bold\",\n",
    "    color=\"#1A224C\",\n",
    "    **args)\n",
    "\n",
    "left = -2.75\n",
    "ax[0].text(left+0.005, 1.55, '1',\n",
    "    horizontalalignment='left',\n",
    "    verticalalignment='bottom',\n",
    "    weight=\"bold\",\n",
    "    color=\"#1A224C\",\n",
    "    **args)\n",
    "\n",
    "ax[0].text(left, 4.62, '2',\n",
    "    horizontalalignment='left',\n",
    "    verticalalignment='bottom',\n",
    "    weight=\"bold\",\n",
    "    color=\"#1A224C\",\n",
    "    **args)\n",
    "\n",
    "ax[0].text(left, 6.62, '3',\n",
    "    horizontalalignment='left',\n",
    "    verticalalignment='bottom',\n",
    "    weight=\"bold\",\n",
    "    color=\"#1A224C\",\n",
    "    **args)\n",
    "\n",
    "\n",
    "plt.tight_layout(w_pad=0.11)\n",
    "time = utils.timenow()\n",
    "plt.savefig(f'multiple_groups/temp_{time}_corr_different_ways_of_grouping_LLM.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intersect",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
